{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain faiss-cpu pypdf GitPython openpyxl sentence-transformers transformers llama-cpp-python > /dev/null\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import (\n",
    "    LlamaCppEmbeddings, \n",
    "    HuggingFaceEmbeddings, \n",
    "    SentenceTransformerEmbeddings\n",
    ")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    DataFrameLoader,\n",
    "    GitLoader\n",
    "  )\n",
    "import pandas as pd\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_text_splits(text_file):\n",
    "  \"\"\"Function takes in the text data and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  with open(text_file,'r') as txt:\n",
    "    data = txt.read()\n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = textSplit.split_text(data)\n",
    "  return doc_list\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"fastfacts-what-is-climate-change.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What Is Climate Change?\\n1. Climate change  can be a natural process where temperature, rainfall, wind and \\nother elements vary over decades or more. In millions of years, our world has been \\nwarmer and colder than it is now. But today we are experiencing rapid warming from \\nhuman activities, primarily due to burning fossil fuels that generate greenhouse gas \\nemissions.\\n2. Increasing greenhouse gas emissions  from human activity act like a blanket \\nwrapped around the earth, trapping the sun’s heat and raising temperatures.\\n3. Examples of greenhouse gas emissions that are causing climate change include \\ncarbon dioxide and methane. These come from burning fossil fuels such as gasoline \\nfor driving a car or coal for heating a building. Clearing land and forests can also \\nrelease carbon dioxide. Landfills for garbage are another source. Energy, industry, \\nagriculture and waste disposal are among the major emitters.\\n4. Greenhouse gas concentrations are at their highest levels in 2 million years  and \\ncontinue to rise. As a result, the earth is about 1.1°C warmer than it was in the 1800s. \\nThe last decade was the warmest on record. \\n5. Many people think climate change mainly means warmer temperatures. But \\ntemperature rise is only the beginning of the story. Because the Earth is a system, \\nwhere everything is connected, changes in one area can influence changes in all \\nothers. The consequences of climate change  now include, among others, intense \\ndroughts, water scarcity, severe fires, rising sea levels, flooding, melting polar ice, \\ncatastrophic storms and declining biodiversity.\\n6. People are experiencing climate change in diverse ways. It affects our health, \\nability to grow food, housing, safety and work. Some of us are already more vulnerable \\nto climate impacts, such as people living in small island developing States. Conditions \\nlike sea-level rise and saltwater intrusion have advanced to the point where whole \\ncommunities have had to relocate. In the future, the number of “climate refugees” is \\nexpected to rise.\\n7. Every increase in global warming matters.  In a 2018 report, thousands of scientists \\nand government reviewers agreed that limiting global temperature rise to no more \\nthan 1.5°C would help us avoid the worst climate impacts and maintain a livable \\nclimate. Yet the current path of carbon dioxide emissions could increase global \\ntemperature by as much as 4.4°C by the end of the century . \\nFAST FACTSFAST FACTS'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pdf_splits(pdf_file):\n",
    "  \"\"\"Function takes in the pdf data and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  \n",
    "  loader = PyPDFLoader(pdf_file)\n",
    "  pages = loader.load_and_split()  \n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = []\n",
    "  #Pages will be list of pages, so need to modify the loop\n",
    "  for pg in pages:\n",
    "    pg_splits = textSplit.split_text(pg.page_content)\n",
    "    doc_list.extend(pg_splits)\n",
    "\n",
    "  return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_excel_splits(excel_file,target_col,sheet_name):\n",
    "  trialDF = pd.read_excel(io=excel_file,\n",
    "                          engine='openpyxl',\n",
    "                          sheet_name=sheet_name)\n",
    "  \n",
    "  df_loader = DataFrameLoader(trialDF,\n",
    "                              page_content_column=target_col)\n",
    "  \n",
    "  excel_docs = df_loader.load()\n",
    "\n",
    "  return excel_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_csv_splits(csv_file):\n",
    "  \"\"\"Function takes in the csv and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  csvLoader = CSVLoader(csv_file)\n",
    "  csvdocs = csvLoader.load()\n",
    "  return csvdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ipynb_splits(notebook):\n",
    "  \"\"\"Function takes the notebook file,reads the file \n",
    "  data as python script, then splits script data directly\"\"\"\n",
    "\n",
    "  with open(notebook) as fh:\n",
    "    nb = nbformat.reads(fh.read(), nbformat.NO_CONVERT)\n",
    "\n",
    "  exporter = PythonExporter()\n",
    "  source, meta = exporter.from_notebook_node(nb)\n",
    "\n",
    "  #Python file data is in the source variable\n",
    "  \n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = textSplit.split_text(source)\n",
    "  return doc_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_git_files(repo_link, folder_path, file_ext):\n",
    "  # eg. loading only python files\n",
    "  git_loader = GitLoader(clone_url=repo_link,\n",
    "    repo_path=folder_path, \n",
    "    file_filter=lambda file_path: file_path.endswith(file_ext))\n",
    "  #Will take each file individual document\n",
    "  git_docs = git_loader.load()\n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = []\n",
    "  #Pages will be list of pages, so need to modify the loop\n",
    "  for code in git_docs:\n",
    "    code_splits = textSplit.split_text(code.page_content)\n",
    "    doc_list.extend(code_splits)\n",
    "\n",
    "  return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_index(doc_list, embed_fn, index_store):\n",
    "  \"\"\"Function takes in existing vector_store, \n",
    "  new doc_list and embedding function that is \n",
    "  initialized on appropriate model. Local or online. \n",
    "  New embedding is merged with the existing index. If no \n",
    "  index given a new one is created\"\"\"\n",
    "  #check whether the doc_list is documents, or text\n",
    "  try:\n",
    "    faiss_db = FAISS.from_documents(doc_list, \n",
    "                              embed_fn)  \n",
    "  except Exception as e:\n",
    "    faiss_db = FAISS.from_texts(doc_list, \n",
    "                              embed_fn)\n",
    "  \n",
    "  if os.path.exists(index_store):\n",
    "    local_db = FAISS.load_local(index_store,embed_fn)\n",
    "    #merging the new embedding with the existing index store\n",
    "    local_db.merge_from(faiss_db)\n",
    "    print(\"Merge completed\")\n",
    "    local_db.save_local(index_store)\n",
    "    print(\"Updated index saved\")\n",
    "  else:\n",
    "    faiss_db.save_local(folder_path=index_store)\n",
    "    print(\"New store created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_length(index_path, embed_fn):\n",
    "  test_index = FAISS.load_local(index_path,\n",
    "                              embeddings=embed_fn)\n",
    "  test_dict = test_index.docstore._dict\n",
    "  return len(test_dict.values())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#testing out the above function with the open source \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_docs=get_pdf_splits(\"fastfacts-what-is-climate-change.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(mail_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What Is Climate Change?\\n1. Climate change  can be a natural process where temperature, rainfall, wind and'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mail_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed\n",
      "Updated index saved\n"
     ]
    }
   ],
   "source": [
    "'Space via IFTTT <action@ifttt.com>\\nAstronomy Picture of the Day:'\n",
    "\n",
    "faiss_db = embed_index(doc_list=mail_docs,\n",
    "            embed_fn=embeddings,\n",
    "            index_store='new_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_docs_length(index_path='new_index',embed_fn=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_idex = FAISS.load_local(\"new_index\",embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='wrapped around the earth, trapping the sun’s heat and raising temperatures.', metadata={}),\n",
       " Document(page_content='where everything is connected, changes in one area can influence changes in all', metadata={}),\n",
       " Document(page_content='like sea-level rise and saltwater intrusion have advanced to the point where whole', metadata={}),\n",
       " Document(page_content='temperature rise is only the beginning of the story. Because the Earth is a system,', metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idex.similarity_search(\"Stellar Nursery in Perseus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='release carbon dioxide. Landfills for garbage are another source. Energy, industry, \\nagriculture and waste disposal are among the major emitters.', metadata={}),\n",
       " Document(page_content='other elements vary over decades or more. In millions of years, our world has been', metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\"\n",
    "test_idex.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.retrievers import SVMRetriever\n",
    "\n",
    "# svm_retriever = SVMRetriever.from_documents(all_splits,OpenAIEmbeddings())\n",
    "# docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "# len(docs_svm)\n",
    "vectordb=test_idex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import base64\n",
    "import textwrap\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings,HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma,FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @st.cache_resource\n",
    "\n",
    "checkpoint = \"LaMini-T5-738M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype= torch.float32\n",
    ")\n",
    "\n",
    "# @st.cache_resource\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text2text-generation',\n",
    "    model = base_model,\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 256,\n",
    "    do_sample = True,\n",
    "    temperature = 0.3,\n",
    "    top_p = 0.95\n",
    ")\n",
    "local_llm= HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Major topics for this class include infrastructure and natural ecosystems, climate change, and the Paris Agreement.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, probability is not a class topic.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='5. Many people think climate change mainly means warmer temperatures. But', metadata={})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The passage states that adaptation will be required everywhere, but must be prioritized now for the most vulnerable people with the fewest resources to cope with climate hazards.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
